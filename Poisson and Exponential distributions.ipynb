{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this excercise is to split data automatically into two parts, after a change in trend, assuming those are count related data from Poisson distributions with different lambdas. This excercise is not original and follows the concepts of book Probabilistic-Programming-and-Bayesian-Methods-for-Hackers and PYMC tutorial https://pymc-devs.github.io/pymc/tutorial.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('bmh')\n",
    "colours = ['#bd345d', '#7a68a6', '#467821']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate data from Poisson probability distributions with two different lambda paramaters. We will draw lambda from exponential distribution and threshold from discrete uniform disctribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#specify params of your data\n",
    "total_observations = 100\n",
    "lambda_exp = 0.25\n",
    "\n",
    "lam_1 = np.random.exponential(1/lambda_exp)\n",
    "lam_2 = np.random.exponential(1/lambda_exp)\n",
    "threshold = np.random.random_integers(0.25*total_observations, 0.75*total_observations)\n",
    "\n",
    "print(lam_1, lam_2, threshold)\n",
    "\n",
    "arr_1 = np.random.poisson(lam=lam_1, size=threshold)\n",
    "arr_2 = np.random.poisson(lam=lam_2, size=total_observations-threshold)\n",
    "arr = np.concatenate((arr_1, arr_2))\n",
    "n_arr = total_observations\n",
    "av = 1.0/np.average(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(12.5, 3.5)\n",
    "plt.bar(np.arange(n_arr), arr, color=colours[0])\n",
    "plt.title(\"Our Generated Dataset\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the variables we model should belong to the Model object.\n",
    "\n",
    "We will assume that lambda's are drawn from exponential distribution and the threshold tau is initially drawn from a discrete uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # create lambda_1 and lambda_2 as stochastic variables\n",
    "    # (random number generators)\n",
    "    lambda_1 = pm.Exponential(\"lambda_1\", 1/av)\n",
    "    lambda_2 = pm.Exponential(\"lambda_2\", 1/av)\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=n_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    idx = np.arange(n_arr)\n",
    "    lambda_ = pm.math.switch(tau >= idx, lambda_1, lambda_2)\n",
    "    \n",
    "with model:\n",
    "    observation = pm.Poisson(\"obs\", lambda_, observed=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    step = pm.Metropolis()\n",
    "    trace = pm.sample(1000, tune=500, step=step)\n",
    "    \n",
    "lambda_1_samples = trace['lambda_1']\n",
    "lambda_2_samples = trace['lambda_2']\n",
    "tau_samples = trace['tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    traceplot(trace, [''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(12.5, 10)\n",
    "ax = plt.subplot(311)\n",
    "ax.set_autoscaley_on(False)\n",
    "\n",
    "plt.hist(\n",
    "    lambda_1_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "    label=\"posterior of $\\lambda_1$\", color=colours[0], normed=True,\n",
    ")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(r\"\"\"Posterior distributions of the variables\n",
    "    $\\lambda_1,\\;\\lambda_2,\\;\\tau$\"\"\")\n",
    "plt.xlim(0,10)\n",
    "plt.xlabel(\"$\\lambda_1$ value\")\n",
    "\n",
    "ax = plt.subplot(312)\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.hist(\n",
    "    lambda_2_samples, histtype='stepfilled', bins=30, alpha=0.85,\n",
    "    label=\"posterior of $\\lambda_2$\", color=colours[1], normed=True,\n",
    ")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlim(0,10)\n",
    "plt.xlabel(\"$\\lambda_2$ value\")\n",
    "\n",
    "plt.subplot(313)\n",
    "w = 1.0 / tau_samples.shape[0] * np.ones_like(tau_samples)\n",
    "plt.hist(\n",
    "    tau_samples, bins=n_arr, alpha=1,\n",
    "    label=r\"posterior of $\\tau$\",\n",
    "    color=colours[2], weights=w, rwidth=2.,\n",
    ")\n",
    "plt.xticks(np.arange(n_arr))\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylim([0, 1])\n",
    "plt.xlim([0, n_arr])\n",
    "plt.xlabel(r\"$\\tau$ (in days)\")\n",
    "plt.ylabel(\"probability\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
